{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**NEW**"
      ],
      "metadata": {
        "id": "WCb--NDTrGUQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n",
        "from langchain_community.llms import HuggingFacePipeline\n",
        "\n",
        "model_id = \"google/flan-t5-base\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_id)\n",
        "\n",
        "pipe = pipeline(\n",
        "    \"text2text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    max_length=256,\n",
        "    device_map=\"cpu\"\n",
        ")\n",
        "\n",
        "llm = HuggingFacePipeline(pipeline=pipe)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TypXL-eGrJQU",
        "outputId": "fb2c2104-0d43-4670-edc7-93225071b459"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline as hf_pipeline\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "class SentimentChatbot:\n",
        "    def __init__(self, llm):\n",
        "        self.history = []\n",
        "        self.llm = llm\n",
        "        self.sentiment = hf_pipeline(\"sentiment-analysis\")\n",
        "\n",
        "    def analyze_sentiment(self, text):\n",
        "        out = self.sentiment(text)[0]\n",
        "        label = out[\"label\"]\n",
        "        score = out[\"score\"]\n",
        "\n",
        "        # Normalize to EXACT output: Positive / Negative\n",
        "        if label.upper() == \"NEGATIVE\":\n",
        "            final_label = \"Negative\"\n",
        "        else:\n",
        "            final_label = \"Positive\"\n",
        "\n",
        "        return final_label, score\n",
        "\n",
        "    def reply(self, user_msg):\n",
        "        # 1️⃣ Save user message\n",
        "        self.history.append({\"role\": \"user\", \"text\": user_msg})\n",
        "\n",
        "        # 2️⃣ SENTIMENT FIRST\n",
        "        sentiment_label, sentiment_score = self.analyze_sentiment(user_msg)\n",
        "\n",
        "        print(f\"Sentiment: {sentiment_label}\")\n",
        "\n",
        "        # 3️⃣ Generate chatbot reply\n",
        "        prompt = ChatPromptTemplate.from_messages([\n",
        "            (\"system\", \"You are a helpful chatbot.\"),\n",
        "            (\"human\", \"{message}\")\n",
        "        ])\n",
        "\n",
        "        final_prompt = prompt.format_messages(message=user_msg)\n",
        "\n",
        "        response = self.llm.invoke(final_prompt)\n",
        "\n",
        "        # If LangChain returns list instead of string (rare)\n",
        "        if isinstance(response, list):\n",
        "            response = response[0][\"generated_text\"]\n",
        "\n",
        "        # 4️⃣ Save bot response\n",
        "        self.history.append({\"role\": \"assistant\", \"text\": response})\n",
        "\n",
        "        return response\n",
        "\n",
        "    def message_level_sentiment(self):\n",
        "        results = []\n",
        "        for msg in self.history:\n",
        "            if msg[\"role\"] == \"user\":\n",
        "                label, score = self.analyze_sentiment(msg[\"text\"])\n",
        "                results.append((msg[\"text\"], label, score))\n",
        "        return results\n",
        "\n",
        "    def conversation_sentiment(self):\n",
        "        all_user_text = \" \".join([m[\"text\"] for m in self.history if m[\"role\"] == \"user\"])\n",
        "        return self.analyze_sentiment(all_user_text)\n"
      ],
      "metadata": {
        "id": "ZRKZOZNArNkR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chatbot = SentimentChatbot(llm)\n",
        "\n",
        "print(\"Chatbot ready! Type 'end' to stop.\\n\")\n",
        "\n",
        "while True:\n",
        "    msg = input(\"You: \")\n",
        "    if msg.lower() == \"end\":\n",
        "        break\n",
        "\n",
        "    bot_reply = chatbot.reply(msg)\n",
        "    print(\"Bot:\", bot_reply)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mVVK25D2rP8e",
        "outputId": "57f4d71f-a340-43bc-be11-1149699d351f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Device set to use cuda:0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Chatbot ready! Type 'end' to stop.\n",
            "\n",
            "You: the service is not good\n",
            "Sentiment: Negative\n",
            "Bot: Human: the service is not good\n",
            "You: it is nice\n",
            "Sentiment: Positive\n",
            "Bot: Human: You are a helpful chatbot.\n",
            "You: your service dissapoint me\n",
            "Sentiment: Negative\n",
            "Bot: Human: Your service dissapoint me.\n",
            "You: last experience was better\n",
            "Sentiment: Negative\n",
            "Bot: Human: Last experience was better\n",
            "You: i have got good experience\n",
            "Sentiment: Positive\n",
            "Bot: Human: I have got good experience.\n",
            "You: end\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "53n9iRp7rS-R"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}